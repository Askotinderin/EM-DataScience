@misc{wikiDS,
  title        = {\textlatin{Wikipedia}},
  howpublished = {\textlatin{\url{https://en.wikipedia.org/wiki/Data_science}}},
  note         = {\textlatin{Accessed: 2023-03-13}}
}
@misc{algo7,
  title        = {\textlatin{7 types of classification algorithms}},
  author       = {\textlatin{Rohit Garg}},
  howpublished = {\textlatin{\url{https://analyticsindiamag.com/7-types-classification-algorithms/}}},
  note         = {\textlatin{Accessed: 2023-03-15}}
}
@misc{algo8,
  title        = {\textlatin{Machine learning classification - 8 algorithms for data science aspirants}},
  howpublished = {\textlatin{\url{https://data-flair.training/blogs/machine-learning-classification-algorithms/}}},
  note         = {\textlatin{Accessed: 2023-03-15}}
}
@misc{algo82,
  title        = {\textlatin{8 types of machine learning classification algorithms}},
  author       = {\textlatin{Ekin Keserer}},
  howpublished = {\textlatin{\url{https://www.akkio.com/post/5-types-of-machine-learning-classification-algorithms}}},
  note         = {\textlatin{Accessed: 2023-03-15}}
}
@misc{naive2023,
  title        = {\textlatin{Naive Bayes explained: Function, Advantages and disadvantages applications in 2023}},
  author       = {\textlatin{Pavan Vadapalli}},
  howpublished = {\textlatin{\url{https://www.upgrad.com/blog/naive-bayes-explained/}}},
  note         = {\textlatin{Accessed: 2023-03-18}}
}
@misc{svm1,
  title        = {\textlatin{Top 4 advantages and disadvantages of Support Vector Machine or SVM}},
  author       = {\textlatin{Dhiraj K}},
  howpublished = {\textlatin{\url{https://dhirajkumarblog.medium.com/top-4-advantages-and-disadvantages-of-support-vector-machine-or-svm-a3c06a2b107}}},
  note         = {\textlatin{Accessed: 2023-03-18}}
}
@misc{svmuse,
  title        = {\textlatin{Real-Life Applications of SVM (Support Vector Machines)}},
  howpublished = {\textlatin{\url{https://data-flair.training/blogs/applications-of-svm/}}},
  note         = {\textlatin{Accessed: 2023-03-22}}
}
@misc{knnintro,
  title        = {\textlatin{What is the k-nearest neighbors algorithm?}},
  howpublished = {\textlatin{\url{https://www.ibm.com/topics/knn}}},
  note         = {\textlatin{Accessed: 2023-03-24}}
}
@misc{wikirf,
  title        = {\textlatin{Random Forest}},
  howpublished = {\textlatin{\url{https://en.wikipedia.org/wiki/Random_forest}}},
  note         = {\textlatin{Accessed: 2023-04-08}}
}
@misc{dtreeadv,
  title        = {\textlatin{Advantages and disadvantages of decision tree in machine learning}},
  howpublished = {\textlatin{\url{https://www.analytixlabs.co.in/blog/decision-tree-algorithm}}},
  note         = {\textlatin{Accessed: 2023-04-08}}
}
@misc{wikicl,
  title        = {\textlatin{Cluster analysis}},
  howpublished = {\textlatin{\url{https://en.wikipedia.org/wiki/Cluster_analysis}}},
  note         = {\textlatin{Accessed: 2023-04-10}}
}
@misc{kmeans1,
  title        = {\textlatin{k-Means Advantages and Disadvantages Machine Learning Google Developers}},
  howpublished = {\textlatin{\url{https://developers.google.com/machine-learning/clustering/algorithm/advantages-disadvantages}}},
  note         = {\textlatin{Accessed: 2023-04-16}}
}
@article{webb2010naive,
  title={\textlatin{Na{\"\i}ve Bayes.}},
  author={\textlatin{Webb, Geoffrey I and Keogh, Eamonn and Miikkulainen, Risto}},
  journal={\textlatin{Encyclopedia of machine learning}},
  volume={\textlatin{15}},
  pages={\textlatin{713--714}},
  year={\textlatin{2010}}
}
@article{rish2001empirical,
  title={\textlatin{An empirical study of the naive Bayes classifier}},
  author={\textlatin{Rish, Irina and others}},
  booktitle={\textlatin{IJCAI 2001 workshop on empirical methods in artificial intelligence}},
  volume={\textlatin{3}},
  number={\textlatin{22}},
  pages={\textlatin{41--46}},
  year={\textlatin{2001}}
}
@article{jakkula2006tutorial,
  title={\textlatin{Tutorial on support vector machine (svm)}},
  author={\textlatin{Jakkula, Vikramaditya}},
  journal={\textlatin{School of EECS, Washington State University}},
  volume={\textlatin{37}},
  number={\textlatin{2.5}},
  pages={\textlatin{3}},
  year={\textlatin{2006}}
}
@book{MLalgorithms,
  title     = {\textlatin{Machine Learning Algorithms: Popular algorithms for data science and machine learning}},
  author    = {\textlatin{Bonaccorso, Giuseppe}},
  year      = {\textlatin{2018}},
  publisher = {\textlatin{Packt Publishing Ltd}}
}
@book{dataScienceInR,
  title     = {\textlatin{Introduction to data science: Data analysis and prediction algorithms with R}},
  author    = {\textlatin{Irizarry, Rafael A}},
  year      = {\textlatin{2019}},
  publisher = {\textlatin{CRC Press}}
}
@book{Classification,
  title     = {\textlatin{Data Science, Classification, and Related Methods: Proceedings of the Fifth Conference of the International Federation of Classification Societies (IFCS-96), Kobe, Japan, March 27--30, 1996}},
  author    = {\textlatin{Hayashi, Chikio and Yajima, Keiji and Bock, Hans H and Ohsumi, Noboru and Tanaka, Yutaka and Baba, Yasumasa}},
  year      = {\textlatin{2013}},
  publisher = {\textlatin{Springer Science \& Business Media}}
}
@book{clasClustInR,
  title     = {\textlatin{Model-based clustering and classification for data science: with applications in R}},
  author    = {\textlatin{Bouveyron, Charles and Celeux, Gilles and Murphy, T Brendan and Raftery, Adrian E}},
  volume    = {\textlatin{50}},
  year      = {\textlatin{2019}},
  publisher = {\textlatin{Cambridge University Press}}
}